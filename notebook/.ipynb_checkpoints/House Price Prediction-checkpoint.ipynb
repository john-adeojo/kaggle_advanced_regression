{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a8f978-e9ce-4657-9cf9-d450a370185f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# House Prices - Advanced Regression Techniques\n",
    "\n",
    "* Author: [John Adeojo](https://www.john-adeojo.com/)\n",
    "* Blog: [more projects on my medium blog](https://medium.com/@johnadeojo)\n",
    "* LinkedIn: [Follow me](https://www.linkedin.com/in/john-adeojo/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde541ce-5553-4d49-8925-e51971c61cca",
   "metadata": {},
   "source": [
    "# Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd637c9a-2ea9-49d8-b46e-22b71b29b2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76fcd949-60c9-4be4-a6d3-38d8a859f38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"https://raw.githubusercontent.com/john-adeojo/kaggle_advanced_regression/main/data/01_raw/train%20(3).csv\")\n",
    "df_test = pd.read_csv(r\"https://raw.githubusercontent.com/john-adeojo/kaggle_advanced_regression/main/data/01_raw/test%20(2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3666e015-0bff-4593-85b2-2e73acc994b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17662b53cc964188b26efb9b934b7e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bc09d25d5d4066b25d3fcf9cf473fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46950ae8e0c42a086182c892e2d589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac915f2e68041e9bf2f4efcf52c68ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do some quick data profiling with ydata profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df_train, title=\"Pandas Profiling Report: House Price Data\")\n",
    "profile.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\kaggle-env\\kaggle_advanced_regression\\data\\02_reports\\testprofile_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2271f5a-38d8-47f8-b438-e9e58848df45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82aa896d96cd4de6b8bece046f3677b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddba49cb2b3455a94402ce9682cc711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e32e1529f847afa6d6029dcd165279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf81178c9c449659818ebc26cbaf248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(df_test, title=\"Pandas Profiling Report: House Price Data (Test)\")\n",
    "profile.to_file(r\"C:\\Users\\johna\\anaconda3\\envs\\kaggle-env\\kaggle_advanced_regression\\data\\02_reports\\testprofile_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18488c-46ab-4e43-8009-bc5983ca622d",
   "metadata": {},
   "source": [
    "# Data Wrangling & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cecb78a-d3fa-4634-9d68-f7afccf8a67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define funtion te rplace missing vairbales\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def impute_missing(df, test=False):\n",
    "    \n",
    "    if test == False:\n",
    "        id_df = df['Id']\n",
    "        y = df['SalePrice']\n",
    "        df = df.drop(columns=['Id', 'SalePrice'])\n",
    "    else:\n",
    "        id_df = df['Id']\n",
    "        df = df.drop(columns=['Id'])\n",
    "    \n",
    "    \n",
    "    df['LotFrontage'] = df['LotFrontage'].fillna(0)\n",
    "    df['Alley'] = df['Alley'].fillna('No Alley')\n",
    "    df['MasVnrType'] = df['MasVnrType'].fillna('None')\n",
    "    df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\n",
    "    df['BsmtQual'] = df['BsmtQual'].fillna('None')\n",
    "    df['BsmtCond'] = df['BsmtCond'].fillna('None')\n",
    "    df['BsmtExposure'] = df['BsmtExposure'].fillna('None')\n",
    "    df['BsmtFinType1'] = df['BsmtFinType1'].fillna('None')\n",
    "    df['BsmtFinType2'] = df['BsmtFinType2'].fillna('None')\n",
    "    df['Electrical'] = df['Electrical'].fillna('SBrkr')\n",
    "    df['FireplaceQu'] = df['FireplaceQu'].fillna('None')\n",
    "    df['GarageType'] = df['GarageType'].fillna('None')\n",
    "    df['GarageYrBlt'] = df['GarageYrBlt'].fillna(9999)\n",
    "    df['GarageFinish'] = df['GarageFinish'].fillna('None')\n",
    "    df['GarageQual'] = df['GarageQual'].fillna('None')\n",
    "    df['GarageCond'] = df['GarageCond'].fillna('None')\n",
    "    df['PoolQC'] = df['PoolQC'].fillna('None')\n",
    "    df['Fence'] = df['Fence'].fillna('None')\n",
    "    df['MiscFeature'] = df['MiscFeature'].fillna('None')\n",
    "    \n",
    "    # missing in test \n",
    "    df['MSZoning'] = df['MSZoning'].fillna('RL')\n",
    "    df['Utilities'] = df['Utilities'].fillna('AllPub')\n",
    "    df['Exterior1st'] = df['Exterior1st'].fillna('VinylSd')  # replace with mode for area.\n",
    "    df['Exterior2nd'] = df['Exterior2nd'].fillna('VinylSd')  # replace with mode for area.\n",
    "    df['BsmtFinSF1'] = df['BsmtFinSF1'].fillna(0) # effectively no basement\n",
    "    df['BsmtFinSF2'] = df['BsmtFinSF2'].fillna(0)\n",
    "    df['BsmtUnfSF'] = df['BsmtUnfSF'].fillna(0)\n",
    "    df['BsmtUnfSF'] = df['BsmtUnfSF'].fillna(0)\n",
    "    df['TotalBsmtSF'] = df['TotalBsmtSF'].fillna(0)\n",
    "    df['BsmtFullBath'] = df['BsmtFullBath'].fillna(0)\n",
    "    df['KitchenQual'] = df['KitchenQual'].fillna('TA')\n",
    "    df['Functional'] = df['Functional'].fillna('Typ')\n",
    "    df['Functional'] = df['Functional'].fillna('Typ')\n",
    "    df['GarageCars'] = df['GarageCars'].fillna(0)\n",
    "    df['GarageArea'] = df['GarageArea'].fillna(0) # if\n",
    "    df['SaleType'] = df['SaleType'].fillna('WD') # if\n",
    "    \n",
    "    # convert int to object\n",
    "    df['YearBuilt'] = df['YearBuilt'].astype('object')\n",
    "    df['YearRemodAdd'] = df['YearRemodAdd'].astype('object')\n",
    "    df['GarageYrBlt'] = df['GarageYrBlt'].astype('object')\n",
    "    df['YrSold'] = df['YrSold'].astype('object')\n",
    "\n",
    "\n",
    "    \n",
    "    if test == False:\n",
    "        return df, y, id_df\n",
    "    else:\n",
    "        return df, id_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e97e1f5-2077-44e3-947e-c3a7b40529a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y, train_id = impute_missing(df_train, test=False)\n",
    "X_test, test_id = impute_missing(df_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6813faf0-2dca-4ae5-8218-882bc3be05e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify categorical and numeric columns\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_features = X.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52bdc433-986c-4f37-b336-b46e1fd17e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from umap import UMAP\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# construct the pipeline for data transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
    "        ('num', StandardScaler(), num_features)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('umap', UMAP(n_components=2))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84c2b2e8-70f4-4480-b939-bd0d1b8535e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split data \n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f2bb9ab-61d0-42f1-a521-3e89152d4d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m X_train_trasnformed \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[0;32m      8\u001b[0m X_validation_trasnformed \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(X_validation)\n\u001b[1;32m----> 9\u001b[0m X_test_trasnformed \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\sklearn\\pipeline.py:635\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    633\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[1;32m--> 635\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\umap\\umap_.py:2807\u001b[0m, in \u001b[0;36mUMAP.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2804\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransform unavailable when model was fit with only a single data sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2805\u001b[0m     )\n\u001b[0;32m   2806\u001b[0m \u001b[38;5;66;03m# If we just have the original input then short circuit things\u001b[39;00m\n\u001b[1;32m-> 2807\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2808\u001b[0m x_hash \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mhash(X)\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_hash \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_hash:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\sklearn\\utils\\validation.py:822\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    821\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 822\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\sklearn\\utils\\validation.py:551\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    546\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    547\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt check \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m sparse matrix for nan or inf.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m spmatrix\u001b[38;5;241m.\u001b[39mformat,\n\u001b[0;32m    548\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    549\u001b[0m         )\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spmatrix\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# run the pipeline\n",
    "\n",
    "# fit pipeline on train\n",
    "pipeline.fit(X_train)\n",
    "\n",
    "# transform on train, test and validation\n",
    "X_train_trasnformed = pipeline.transform(X_train)\n",
    "X_validation_trasnformed = pipeline.transform(X_validation)\n",
    "X_test_trasnformed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec181ef-3adb-4970-9684-d556cc6a6eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
